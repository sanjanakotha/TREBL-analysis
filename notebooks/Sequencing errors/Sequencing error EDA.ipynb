{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC Library\n",
    "What are the Hamming distances between designed tiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What is the distance between HawkBCss?\n",
    "# initial_HawkBCs_qual = initial[initial[\"HawkBCs_qual\"] == True]\n",
    "# initial_HawkBCs_qual_counts = pd.DataFrame(initial_HawkBCs_qual[\"HawkBCs\"].value_counts()).reset_index()\n",
    "# initial_HawkBCs_qual_unique = initial_HawkBCs_qual_counts[\"HawkBCs\"]\n",
    "# HawkBCs_dist = nearest_neighbors_parallel_df(list(initial_HawkBCs_qual_unique))\n",
    "# HawkBCs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_file = pd.read_csv(\"../../data/DNA_Tiles_nkx2_2.txt\",header=None)\n",
    "design_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_min_hamming_dist(seq_list):\n",
    "#     # Step 1: Convert to 2D char array\n",
    "#     seq_array = np.array([list(seq) for seq in seq_list])\n",
    "\n",
    "#     # Step 2: Compute pairwise Hamming distances\n",
    "#     dist_matrix = pdist(seq_array, metric=lambda u, v: np.sum(u != v))\n",
    "#     dist_matrix_square = squareform(dist_matrix)\n",
    "\n",
    "#     # Step 3: Set diagonal to inf and compute minimum per sequence\n",
    "#     np.fill_diagonal(dist_matrix_square, np.inf)\n",
    "#     min_pairwise_distances = np.min(dist_matrix_square, axis=1)\n",
    "\n",
    "#     # Step 4: Combine tiles and min distances into a DataFrame\n",
    "#     df = pd.DataFrame({\n",
    "#         'Tile': seq_list,\n",
    "#         'Min_Hamming_Distance': min_pairwise_distances\n",
    "#     })\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hamming_distance(seq1, seq2):\n",
    "#     \"\"\"Compute Hamming distance between two equal-length sequences.\"\"\"\n",
    "#     return sum(c1 != c2 for c1, c2 in zip(seq1, seq2))\n",
    "\n",
    "# def add_min_hamming_dist(query_seqs, ref_seqs=None, n_jobs=-1, batch_size=100):\n",
    "#     \"\"\"\n",
    "#     Compute the minimum Hamming distance for each sequence in query_seqs \n",
    "#     against all sequences in ref_seqs (or within query_seqs if ref_seqs is None).\n",
    "\n",
    "#     Args:\n",
    "#         query_seqs (list[str]): Sequences to evaluate.\n",
    "#         ref_seqs (list[str] | None): Reference sequences. If None, use query_seqs.\n",
    "#         n_jobs (int): Number of parallel jobs (default = -1, all cores).\n",
    "#         batch_size (int): Chunk size for parallelization.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: query sequence + min hamming distance.\n",
    "#     \"\"\"\n",
    "#     if ref_seqs is None:\n",
    "#         ref_seqs = query_seqs\n",
    "    \n",
    "#     # Ensure array format\n",
    "#     query_seqs = np.array(query_seqs)\n",
    "#     ref_seqs = np.array(ref_seqs)\n",
    "\n",
    "#     def min_dist_for_seq(seq, ref_seqs):\n",
    "#         dists = (hamming_distance(seq, ref) for ref in ref_seqs if ref != seq)\n",
    "#         return min(dists, default=np.inf)\n",
    "\n",
    "#     # Parallel with progress bar\n",
    "#     results = Parallel(n_jobs=n_jobs, batch_size=batch_size)(\n",
    "#         delayed(min_dist_for_seq)(seq, ref_seqs) for seq in tqdm(query_seqs, desc=\"Computing min Hamming\")\n",
    "#     )\n",
    "\n",
    "#     return pd.DataFrame({\n",
    "#         \"Tile\": query_seqs,\n",
    "#         \"Min_Hamming_Distance\": results\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rapidfuzz.distance import Hamming\n",
    "\n",
    "def add_min_hamming_dist(query_seqs, ref_seqs=None, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Compute the minimum Hamming distance for each sequence in query_seqs\n",
    "    against all sequences in ref_seqs (or within query_seqs if ref_seqs is None).\n",
    "\n",
    "    Args:\n",
    "        query_seqs (list[str]): Sequences to evaluate.\n",
    "        ref_seqs (list[str] | None): Reference sequences. If None, use query_seqs.\n",
    "        batch_size (int): Number of queries to process at once.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: query sequence + min hamming distance.\n",
    "    \"\"\"\n",
    "    if ref_seqs is None:\n",
    "        ref_seqs = query_seqs\n",
    "\n",
    "    query_seqs = np.array(query_seqs, dtype=\"U\")\n",
    "    ref_seqs = np.array(ref_seqs, dtype=\"U\")\n",
    "\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(query_seqs), batch_size), desc=\"Computing min Hamming\"):\n",
    "        batch = query_seqs[i:i+batch_size]\n",
    "        for q in batch:\n",
    "            dists = (Hamming.distance(q, r) for r in ref_seqs if r != q)\n",
    "            results.append(min(dists, default=np.inf))\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Tile\": query_seqs,\n",
    "        \"Min_Hamming_Distance\": results\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_design_file = pd.read_csv(\"../../data/a10_designfile.csv\")\n",
    "EC_design_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How similar are Emily's sequences to one another?\n",
    "# EC_df = add_min_hamming_dist(EC_design_file[\"ArrayDNA\"])\n",
    "# EC_df.to_csv(\"../data/EC_design_file_hamming_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_df = pd.read_csv(\"../../data/EC_design_file_hamming_dist.csv\", index_col = 0)\n",
    "EC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% of sequences in Emily's library have a minimum hamming distance over 6\n",
    "EC_df[EC_df[\"Min_Hamming_Distance\"] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_df[\"Min_Hamming_Distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Emily's Design File\")\n",
    "sns.histplot(EC_df[\"Min_Hamming_Distance\"], binwidth = 1)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC_df = add_min_hamming_dist(design_file[0])\n",
    "CC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC_df[CC_df[\"Min_Hamming_Distance\"] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC_df[\"Min_Hamming_Distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 25% of sequences in Caitlin's design file have hamming distance over 6\n",
    "CC_df[CC_df[\"Min_Hamming_Distance\"] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Caitlin's Design File\")\n",
    "sns.histplot(CC_df[\"Min_Hamming_Distance\"], binwidth = 1)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(dpi = 300, figsize = (6,4))\n",
    "sns.histplot(EC_df[\"Min_Hamming_Distance\"], binwidth = 1, stat = 'density', label = \"GCN4\")\n",
    "sns.histplot(CC_df[\"Min_Hamming_Distance\"], binwidth = 1, stat = 'density', alpha = 0, edgecolor = 'none')\n",
    "plt.xlabel(\"Minimum Hamming Distance\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(dpi = 300, figsize = (6,4))\n",
    "sns.histplot(EC_df[\"Min_Hamming_Distance\"], binwidth = 1, stat = 'density', label = \"GCN4\")\n",
    "sns.histplot(CC_df[\"Min_Hamming_Distance\"], binwidth = 1, stat = 'density', label = \"NKX2-2\")\n",
    "plt.xlabel(\"Minimum Hamming Distance\")\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does each AD have only 1 Hawkins BC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dask.diagnostics import ProgressBar\n",
    "import duckdb\n",
    "\n",
    "os.chdir(\"../scripts\")\n",
    "from mapping import BarcodeMapper\n",
    "from map_refiner import MapRefiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = BarcodeMapper(['../data/Staller_Tl4s1_MVS_0035_I1TTGTCACCAA_CGCACGAACA_S326.fastq.gz.assembled.fastq'],\n",
    "                        \"../data/DNA_Tiles_nkx2_2.txt\",\n",
    "                        [\"ADBC2\", \"HawkBCs\", \"RTBC\", \"AD\"],\n",
    "                        [\"CTCGAGATAACTTCGTATAATGTATGCTAT\", \"GAGCTCGCTAGC\", \"GGCCGGCCATAGGGCCCC\", \"CACCATG\"],\n",
    "                        [\"GGCCGGCCATAGGGCCCC\", \"CTCGAGATAA\", \"GCGGTCCA\", \"GGATCCG\"],\n",
    "                        [6, 9, 16, 162],\n",
    "                      reverse_complement=False)\n",
    "mapped_df = mapper.create_map()\n",
    "mapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.save_parquet('../output/CC_nkx2_2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refiner = MapRefiner(db_path = \"../duckdb/CC_nkx2_2\",\n",
    "                      cols = [\"ADBC2\", \"HawkBCs\", \"RTBC\", \"AD\"],\n",
    "                     reads_threshold = 5,\n",
    "                     column_pairs = [(\"AD\", (\"ADBC2\", \"HawkBCs\")), ((\"ADBC2\", \"HawkBCs\"), \"RTBC\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refiner.create_map1_initial('../output/CC_nkx2_2.parquet/*')\n",
    "initial = refiner.get_map_df('map1_initial')\n",
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial map must have correct length of AD, ADBC2, Hawk BC, and RTBC\n",
    "quality = initial[(initial[\"ADBC2_qual\"] == True) & (initial[\"HawkBCs_qual\"] == True) & (initial[\"RTBC_qual\"] == True) & (initial[\"AD_qual\"] == True)]\n",
    "quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_designed = quality[quality[\"Designed\"] == 1]\n",
    "quality_designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 300)\n",
    "sns.histplot(quality_designed[\"AD\"].value_counts(), binwidth = 20)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(quality_designed[\"AD\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_not_designed = quality[quality[\"Designed\"] == 0]\n",
    "quality_not_designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def min_hamming_distance_parallel(seq_list, ref_list, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Compute minimum Hamming distance from each sequence in seq_list to ref_list\n",
    "    in parallel with a progress bar.\n",
    "    \n",
    "    Returns a DataFrame with Sequence and Min_Hamming_Distance.\n",
    "    \"\"\"\n",
    "    # Filter out \"0\" in ref_list\n",
    "    ref_list = [s for s in ref_list if s != \"0\"]\n",
    "\n",
    "    # Convert to 2D char arrays\n",
    "    seq_array = np.array([list(seq) for seq in seq_list])\n",
    "    ref_array = np.array([list(seq) for seq in ref_list])\n",
    "\n",
    "    if seq_array.shape[1] != ref_array.shape[1]:\n",
    "        raise ValueError(\"Sequences are not all the same length.\")\n",
    "\n",
    "    # Function to compute min Hamming for one sequence\n",
    "    def compute_min(i):\n",
    "        dists = np.sum(seq_array[i] != ref_array, axis=1)\n",
    "        return dists.min()\n",
    "\n",
    "    # Parallel computation with tqdm\n",
    "    min_distances = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(lambda i: compute_min(i))(i) for i in tqdm(range(seq_array.shape[0]))\n",
    "    )\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Sequence': seq_list,\n",
    "        'Min_Hamming_Distance': min_distances\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distance between reads which pass quality check and are designed vs not designed?\n",
    "quality_not_designed_dist = min_hamming_distance_parallel(quality_not_designed[\"AD\"], quality_designed[\"AD\"])\n",
    "quality_not_designed_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_not_designed_dist[\"Min_Hamming_Distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(quality_not_designed_dist[\"Min_Hamming_Distance\"], binwidth = 1, edgecolor = 'none')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_0_reads = (1 - 0.001) ** 120\n",
    "P_1_read = 120 * (0.001) * (1 - (0.001)) ** 119\n",
    "P_2_reads = 120 * (0.001 / 3) ** 2 * ((1 - (0.001 / 3)) ** 119) ** 2\n",
    "P_3_reads = 120 * (0.001 / 3) ** 3 * ((1 - (0.001 / 3)) ** 119) ** 3\n",
    "P_4_reads = 120 * (0.001 / 3) ** 4 * ((1 - (0.001 / 3)) ** 119) ** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - P_0_reads - P_1_read - P_2_reads - P_3_reads - P_4_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200 * (1 - P_0_reads - P_1_read - P_2_reads - P_3_reads - P_4_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_not_designed_dist[quality_not_designed_dist[\"Min_Hamming_Distance\"] == 1][\"Sequence\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality[quality[\"AD\"] == \"AGCCTGCTGGGCCAGAGCATGGACGAGAGCGGCCTGCCTCAGCTGACCAGCTACGACTGCGAGGTGAACGCTCCCATCCAGGGCAGCAGAAACCTGCTGCAGGGCGAGGAGCTGCTGAGAGCCCTGGACCAGGTGAACGGCAGCGGCAGCGGCAGCGGCAGC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_hawk = quality[quality[\"HawkBCs\"] == \"CCACAGAAC\"]\n",
    "shared_hawk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_designed[quality_designed[\"HawkBCs\"] == \"CCACAGAAC\"][\"AD\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_designed[quality_designed[\"AD\"] == \"AGACTGCTGGGCCAGAGCATGGACGAGAGCGGCCTGCCTCAGCTGACCAGCTACGACTGCGAGGTGAACGCTCCCATCCAGGGCAGCGACAACCTGCTGCAGGGCGAGGAGCTGCTGGACGCCCTGGACCAGGTGAACGGCAGCGGCAGCGGCAGCGGCAGC\"][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hamming_distance_parallel(quality_not_designed[quality_not_designed[\"HawkBCs\"] == \"AAGTTAGCC\"][\"AD\"], quality_designed[quality_designed[\"HawkBCs\"] == \"AAGTTAGCC\"][\"AD\"])#[\"Min_Hamming_Distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many reads which are not designed are close to designed\n",
    "quality_not_designed_dist[\"Min_Hamming_Distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hawkins BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Hawk BCs per AD?\n",
    "hawk_bcs_count = initial[[\"AD\", \"HawkBCs\"]].drop_duplicates().groupby(\"AD\").count()\n",
    "hawk_bcs_count.rename(columns={\"HawkBCs\": \"HawkBCs_Count\"}, inplace=True)\n",
    "hawk_bcs_count = hawk_bcs_count.reset_index()\n",
    "hawk_bcs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hawk_bcs_count[\"HawkBCs_Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the BCs look like if an AD has multiple -- some seem like sequencing errors, and others are distinct\n",
    "\n",
    "# Distinct\n",
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 2][\"AD\"].iloc[3] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing error\n",
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 2][\"AD\"].iloc[0] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Distinct\n",
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 3][\"AD\"].iloc[2] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 4][\"AD\"].iloc[0] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 5][\"AD\"].iloc[0] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 6][\"AD\"].iloc[0] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial[initial[\"AD\"] == hawk_bcs_count[hawk_bcs_count[\"HawkBCs_Count\"] == 69][\"AD\"].iloc[0] ][\"HawkBCs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority of rows only have 1 HawkBC\n",
    "# So maybe if a row has multiple Hawk BCs, those are sequencing errors -- OR switching of BCs via recombination\n",
    "hawk_bcs_count[\"HawkBCs_Count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the distribution of average hamming distances between ADs that share a reporter BC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_no_na = quality.dropna()\n",
    "initial_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs = initial_no_na[[\"ADBC2\", \"AD\"]].value_counts().reset_index()\n",
    "initial_ad_bc_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs[\"ADBC2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Example hamming distance function\n",
    "def hamming_distance(seq1, seq2):\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(seq1, seq2))\n",
    "\n",
    "def hamming_to_most_frequent(group):\n",
    "    \"\"\"\n",
    "    For one group of ADs with the same ADBC2:\n",
    "    - Find AD with most count\n",
    "    - Compute hamming distance of all ADs to that AD\n",
    "    \"\"\"\n",
    "    # pick most_frequent AD = highest count\n",
    "    most_frequent_row = group.loc[group[\"count\"].idxmax()]\n",
    "    most_frequent_ad = most_frequent_row[\"AD\"]\n",
    "\n",
    "    # compute distances to most_frequent\n",
    "    distances = group[\"AD\"].apply(lambda s: hamming_distance(s, most_frequent_ad))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"ADBC2\": group[\"ADBC2\"].iloc[0],\n",
    "        \"AD\": group[\"AD\"],\n",
    "        \"count\": group[\"count\"],\n",
    "        \"Hamming_to_most_frequent\": distances\n",
    "    })\n",
    "\n",
    "# --- Parallel execution ---\n",
    "groups = [g for _, g in initial_ad_bc_pairs.groupby(\"ADBC2\")]\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(hamming_to_most_frequent)(group) for group in tqdm(groups, desc=\"Computing distances\")\n",
    ")\n",
    "\n",
    "# Concatenate results\n",
    "dist_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# # Quick summary\n",
    "# print(dist_df.head())\n",
    "\n",
    "# # Example distribution plot\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(dist_df[\"Hamming_to_most_frequent\"], bins=50)\n",
    "# plt.xlabel(\"Hamming distance to most_frequent AD\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"Distribution of distances per ADBC2\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data = dist_df, x = \"count\", y = \"Hamming_to_most_frequent\", s = 3, edgecolor = \"none\", alpha = 0.1)\n",
    "plt.xlabel(\"Reads\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(dist_df[\"Hamming_to_most_frequent\"], binwidth = 1)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists = pd.merge(initial_ad_bc_pairs, dist_df)\n",
    "initial_ad_bc_pairs_with_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average Hamming distance to the most frequent sequence per ADBC2\n",
    "avg_hamming_per_adbc2 = initial_ad_bc_pairs_with_dists.groupby(\"ADBC2\")[\"Hamming_to_most_frequent\"].transform(\"mean\")\n",
    "\n",
    "# Add the calculated column to the DataFrame\n",
    "initial_ad_bc_pairs_with_dists[\"Avg_Hamming_to_Most_Frequent\"] = avg_hamming_per_adbc2\n",
    "initial_ad_bc_pairs_with_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dom_reads = initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"Hamming_to_most_frequent\"] > 0]\n",
    "non_dom_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dom_reads[non_dom_reads[\"count\"] > 5].sort_values(by = \"Avg_Hamming_to_Most_Frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(non_dom_reads[non_dom_reads[\"count\"] < 5][\"Hamming_to_most_frequent\"], binwidth = 1)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"GAACAA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"GTGTGA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dom_reads[non_dom_reads[\"count\"] < 5].sort_values(by = [\"Hamming_to_most_frequent\", \"Avg_Hamming_to_Most_Frequent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"GGTGGT\"][\"AD\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"ATAAAC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dom_reads[non_dom_reads[\"count\"] > 5].sort_values(by = \"Hamming_to_most_frequent\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"TGAGTT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"TGAGTT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"GAAGAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there BCs with low average Hamming distances and high counts?\n",
    "low_hamming_bcs_high_counts = initial_ad_bc_pairs_with_dists[\n",
    "    (initial_ad_bc_pairs_with_dists[\"Avg_Hamming\"] < 5) & \n",
    "    (initial_ad_bc_pairs_with_dists[\"count\"] > 5)\n",
    "]\n",
    "low_hamming_bcs_high_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs_with_dists[initial_ad_bc_pairs_with_dists[\"ADBC2\"] == \"CCGTAT\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_df[avg_dist_df[\"Avg_Hamming\"] <5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs[initial_ad_bc_pairs[\"ADBC2\"] == \"AAAAGT\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs[initial_ad_bc_pairs[\"ADBC2\"] == \"TTTCCA\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs[initial_ad_bc_pairs[\"ADBC2\"] == \"TTTCCA\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ad_bc_pairs[initial_ad_bc_pairs[\"ADBC2\"] == \"TTTGAC\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
