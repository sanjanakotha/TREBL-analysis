{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1481e7-a68d-43b5-abd0-23da4c81d1ad",
   "metadata": {},
   "source": [
    "# General TREBLseq workflow: BC analysis\n",
    "### Some notes from Emily\n",
    "### Some common troubleshooting that comes up:\n",
    "- if subsetting by time or sample gives issues, check whether the df has those values saved as strings or integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47e0c0-57c1-47cc-8e9a-4ffd46a2b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import string\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import glob\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8' )\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a0f52-ec42-4b49-a068-750937970a19",
   "metadata": {},
   "source": [
    "# Step 1: Read in data from RPTRreadsmapper.py and ADreadsmapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900c04c-d8f0-4808-9c5e-a66c17d5d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell:\n",
    "\n",
    "# Output of RPTRreadsmapper.py. nt. if there's a folder of outputs in your current dir: os.path.join(os.getcwd(), 'analyzed_dfs/AD') # ADreadsmapper.py outputs\n",
    "RPTRcsv_directory = '/global/scratch/projects/fc_mvslab/OpenProjects/EChase/TREBLEseq_ismaybethenewcibername/Ciber2_iii/CZB_Sep2024/analyzed_dfs/RPTR' \n",
    "# Output of ADreadsmapper.py. nt:os.path.join(os.getcwd(), 'analyzed_dfs/RPTR') # RPTRreadsmapper.py outputs\n",
    "ADcsv_directory = '/global/scratch/projects/fc_mvslab/OpenProjects/EChase/TREBLEseq_ismaybethenewcibername/Ciber2_iii/CZB_Sep2024/analyzed_dfs/AD' \n",
    "# where your PEAR report is stored\n",
    "pear_f = '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Sep2024/ciber2_iii_MZ001/EC_Ciber2_iii_Gcn4/slurm-21591255.out' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1b5a1-b6b1-4576-aae1-45c11e58e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "ADexperiments_dict = {}\n",
    "\n",
    "# Iterate over files in the directory\n",
    "for filename in os.listdir(ADcsv_directory):\n",
    "#     print(filename)\n",
    "    # Check if the file is a regular file\n",
    "    if os.path.isfile(os.path.join(ADcsv_directory, filename)):\n",
    "        # Assuming all files are CSV, adjust the condition as needed\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read the file into a DataFrame\n",
    "            df = pd.read_csv(os.path.join(ADcsv_directory, filename), index_col=0)\n",
    "\n",
    "            key_value = '_'.join(df.iloc[0]['Library'].split('_')[:3])\n",
    "            df['Library'] = key_value\n",
    "            # Store the DataFrame in the dictionary with the key as the value in column x of row 1\n",
    "            ADexperiments_dict[key_value] = df\n",
    "#             print(key_value)\n",
    "\n",
    "            \n",
    "RPTRexperiments_dict = {}\n",
    "            \n",
    "for filename in os.listdir(RPTRcsv_directory):\n",
    "#     print(filename)\n",
    "    # Check if the file is a regular file\n",
    "    if os.path.isfile(os.path.join(RPTRcsv_directory, filename)):\n",
    "        # Assuming all files are CSV, adjust the condition as needed\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read the file into a DataFrame\n",
    "            df = pd.read_csv(os.path.join(RPTRcsv_directory, filename), index_col=0)\n",
    "            # Get the value in column x of row 1\n",
    "            key_value = '_'.join(df.iloc[0]['Library'].split('_')[:3])\n",
    "            df['Library'] = key_value\n",
    "            # Store the DataFrame in the dictionary with the key as the value in column x of row 1\n",
    "            RPTRexperiments_dict[key_value] = df\n",
    "#             print(key_value)\n",
    "            \n",
    "# Now 'dfs' contains a dictionary where keys are the values in column x of row 1, and values are the corresponding DataFrames\n",
    "\n",
    "\n",
    "# get paired read counts\n",
    "paired = {}\n",
    "lib = None\n",
    "count = None\n",
    "\n",
    "with open (pear_f, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('Assembled reads ...................:'):\n",
    "            count = line.split(':')[1].split('/')[0]\n",
    "            count = locale.atoi(count)\n",
    "            # print(count)\n",
    "        elif line.startswith('Assembled reads file...............:'):\n",
    "            lib = line.split(':')[1].split('/')[1].split('_')[:3]\n",
    "            lib = '_'.join(lib)\n",
    "            # print(lib)\n",
    "        # Only add to the dictionary when both lib and count are defined\n",
    "        if lib and count:\n",
    "            paired[lib] = count\n",
    "            lib = None  # Reset lib and count after storing in the dictionary\n",
    "            count = None\n",
    "\n",
    "\n",
    "# assign total paired to each AD lib\n",
    "for library in ADexperiments_dict.keys(): \n",
    "    # print()\n",
    "    ADexperiments_dict[library]['Allreads'] = paired[library]\n",
    "\n",
    "\n",
    "# assign total paired to each RPTR lib\n",
    "for library in RPTRexperiments_dict.keys():\n",
    "    # print()\n",
    "    RPTRexperiments_dict[library]['Allreads'] = paired[library]\n",
    "\n",
    "\n",
    "merged_dfs = {}\n",
    "\n",
    "for key in ADexperiments_dict.keys():\n",
    "    print(f\" Analyzing library {key}\")\n",
    "    # Extracting the corresponding AD and RPTR dataframes\n",
    "    ad_df = ADexperiments_dict[key]\n",
    "    ad_df_size = ad_df.shape[0]\n",
    "    rptr_df = RPTRexperiments_dict[key.replace(\"AD\", \"RPTR\")]\n",
    "    rptr_df_size = rptr_df.shape[0]\n",
    "\n",
    "    # Merging the dataframes\n",
    "    merged_df = pd.merge(rptr_df, ad_df, \n",
    "                         left_on='BCs', right_on='PutativeRPTR', \n",
    "                         how='inner', suffixes=('_r', '_a'))\n",
    "    merged_df_size = merged_df.shape[0]\n",
    "    print(f'{key} has {merged_df_size} merged entries')\n",
    "    print('%RPTRloss:', (1-merged_df_size/rptr_df_size) * 100)\n",
    "    print('%ADloss:', (1-merged_df_size/ad_df_size) *100)\n",
    "    merged_df = merged_df.drop(['Library_r','PutativeRPTR'], axis=1)\n",
    "    merged_df['R_normalized'] = merged_df['count_r'] / merged_df['Allreads_r'] #create a column that normalizes for read depth\n",
    "    merged_df['A_normalized'] = merged_df['count_a'] / merged_df['Allreads_a'] #create a column that normalizes for read depth\n",
    "    merged_df['Ratio'] = merged_df['R_normalized'] / merged_df['A_normalized']    \n",
    "    merged_df[['Tile', 'AD']] = merged_df['Tile-AD'].str.split('-', expand=True) \n",
    "    merged_df = merged_df.drop(['PutativeTileADBC'], axis=1) \n",
    "    # sequencing errors, drop anything less than 10 reads\n",
    "    merged_df = merged_df[merged_df['count_a']>=10]\n",
    "    merged_df = merged_df[merged_df['count_r']>=10]\n",
    "    print('RPTR BC after filtering:', merged_df.shape[0], '%loss:', ((1-merged_df.shape[0]/merged_df_size)*100))\n",
    "\n",
    "\n",
    "\n",
    "#     Storing the merged dataframe in a dictionary\n",
    "    merged_dfs[key] = merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429dc340-7022-4f64-b9e6-dc7d0d2a302a",
   "metadata": {},
   "source": [
    "# Step 1.1: Read coverage QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c7f2f-298b-4512-99a1-72d8cef9e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "testAD = ADexperiments_dict['AD_4_240']\n",
    "testAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a54cf-7eae-475c-a133-5c5559ae25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(testAD, x='count', log_scale=True)\n",
    "plt.title('AD-ADBC (4.240) coverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83378e09-038b-4ff3-a877-f5e08d54fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "testRPTR = RPTRexperiments_dict['RPTR_4_240']\n",
    "testRPTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1491d0-ec04-4767-8c40-8feacc1eb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(testRPTR, x='count', log_scale=True)\n",
    "plt.title('RPTR BCs (4.240) coverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00354dda-049c-458b-98ee-65ecfe4c4dc0",
   "metadata": {},
   "source": [
    "# Step 2: Group by time & normalize by negative controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0392337-e489-4554-a386-894d78c13331",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = []\n",
    "t5 = []\n",
    "t10 = []\n",
    "t15 = []\n",
    "t30 = []\n",
    "t180 = []\n",
    "t240 = []\n",
    "\n",
    "for key in merged_dfs.keys():\n",
    "    if key.endswith('_5'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t5.append(merged_dfs[key])\n",
    "    if key.endswith('_10'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t10.append(merged_dfs[key])\n",
    "    if key.endswith('_15'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t15.append(merged_dfs[key])  \n",
    "    if key.endswith('_30'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t30.append(merged_dfs[key])\n",
    "    if key.endswith('_180'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t180.append(merged_dfs[key])\n",
    "    if key.endswith('_240'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t240.append(merged_dfs[key])      \n",
    "    if key.endswith('_0'):\n",
    "        # print(key)\n",
    "        merged_dfs[key]['Library'] = key\n",
    "        t0.append(merged_dfs[key])    \n",
    "        \n",
    "t5_all = pd.concat(t5, ignore_index=True)\n",
    "t5_all['R_norm_rpm'] = t5_all['R_normalized']*10e6\n",
    "t5_all['A_norm_rpm'] = t5_all['A_normalized']*10e6\n",
    "t10_all = pd.concat(t10, ignore_index=True)\n",
    "t10_all['R_norm_rpm'] = t10_all['R_normalized']*10e6\n",
    "t10_all['A_norm_rpm'] = t10_all['A_normalized']*10e6\n",
    "t15_all = pd.concat(t15, ignore_index=True)\n",
    "t15_all['R_norm_rpm'] = t15_all['R_normalized']*10e6\n",
    "t15_all['A_norm_rpm'] = t15_all['A_normalized']*10e6\n",
    "t30_all = pd.concat(t30, ignore_index=True)\n",
    "t30_all['R_norm_rpm'] = t30_all['R_normalized']*10e6\n",
    "t30_all['A_norm_rpm'] = t30_all['A_normalized']*10e6\n",
    "t180_all = pd.concat(t180, ignore_index=True)\n",
    "t180_all['R_norm_rpm'] = t180_all['R_normalized']*10e6\n",
    "t180_all['A_norm_rpm'] = t180_all['A_normalized']*10e6\n",
    "t240_all = pd.concat(t240, ignore_index=True)\n",
    "t240_all['R_norm_rpm'] = t240_all['R_normalized']*10e6\n",
    "t240_all['A_norm_rpm'] = t240_all['A_normalized']*10e6\n",
    "t0_all = pd.concat(t0, ignore_index=True)\n",
    "t0_all['R_norm_rpm'] = t0_all['R_normalized']*10e6\n",
    "t0_all['A_norm_rpm'] = t0_all['A_normalized']*10e6\n",
    "\n",
    "# sanity check\n",
    "t10_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bb5cf-4a15-43a9-8cbe-73ecff2f1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df_list = [t0_all, t5_all, t10_all, t15_all, t30_all, t180_all, t240_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa262e-a320-45b8-9440-7cdf4c47d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all negative controls\n",
    "neg_controls_df = pd.read_csv('neg_controls.csv', usecols=['DNAseq'])\n",
    "neg_controls = neg_controls_df['DNAseq'].to_list()\n",
    "\n",
    "for df in time_df_list:\n",
    "    neg_control_mean = df[df['Tile'].isin(neg_controls)]['Ratio'].mean()\n",
    "    df['Ratio_negCTRLnorm'] = df['Ratio']/neg_control_mean\n",
    "\n",
    "concatenated_df = pd.concat(time_df_list, ignore_index=True)\n",
    "concatenated_df['Time'] = concatenated_df['Library_a'].str.split('_').str[-1]\n",
    "concatenated_df['Time'] = pd.to_numeric(concatenated_df['Time'])\n",
    "concatenated_df['sample'] = concatenated_df['Library_a'].str.split('_').str[-2]\n",
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb9360-a73a-4ef9-83f8-25f3fdd0eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint:\n",
    "# concatenated_df.to_csv('rawdata_normalized_<date>.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d4faa-a3df-4cd2-afa5-0aafc75ad2d6",
   "metadata": {},
   "source": [
    "# Step 2.1: Activity score QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7b21b-23a2-4dd3-a16d-fcb776d19ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in facs csv with activity data and control designation (EC did by hand in excel)\n",
    "facs_f='Gcn4OrthologData_ToShare_20240930_EC.csv'\n",
    "facsdf_qc = pd.read_csv(facs_f, usecols=['Name','ArrayDNA','is_control',\n",
    "                                         'Activity_SCglucose', 'TotalReads_BioRepA_BYS4', 'TotalReads_BioRepB_BYS4',\n",
    "                                         'BioRep_A_mCherry','BioRep_A_mCherry_TotalReads','BioRep_B_mCherry','BioRep_B_mCherry_TotalReads', #mCherry 4 bin sorts\n",
    "                                        'BioRep_A_GFP', 'BioRep_A_GFP_TotalReads','BioRep_B_GFP', 'BioRep_B_GFP_TotalReads', #GFP 4 bin sorts -- one of the replicates is very messed up\n",
    "                                        ])\n",
    "\n",
    "facsdf_qc['GFP_mean']=facsdf_qc[['BioRep_A_GFP','BioRep_B_GFP']].mean(axis=1)\n",
    "facsdf_qc['mCherry_mean']=facsdf_qc[['BioRep_A_mCherry','BioRep_B_mCherry']].mean(axis=1)\n",
    "facsdf_qc = facsdf_qc[(\n",
    "    facsdf_qc['BioRep_A_mCherry_TotalReads']>=50) & (facsdf_qc['BioRep_B_mCherry_TotalReads']>=50) &(\n",
    "        facsdf_qc['BioRep_A_GFP_TotalReads']>=50) & (facsdf_qc['BioRep_B_GFP_TotalReads']>=50)\n",
    "    ]\n",
    "facsdf_qc = facsdf_qc[(facsdf_qc['TotalReads_BioRepA_BYS4']>=1000) & (facsdf_qc['TotalReads_BioRepB_BYS4']>=1000) ]\n",
    "facsdf_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfd497-c229-4c7d-aedd-fdff1be027d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrfunc_pair(x, y, **kws):\n",
    "    # Drop NaNs\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    \n",
    "    # Filter to only positive values for log transformation\n",
    "    positive_mask = mask & (x > 0) & (y > 0)\n",
    "\n",
    "    if np.sum(positive_mask) == 0:\n",
    "        spearman_r = 0\n",
    "        pearson_r = 0\n",
    "    else:\n",
    "        # Log-transform the values\n",
    "        x_log = np.log10(x[positive_mask])\n",
    "        y_log = np.log10(y[positive_mask])\n",
    "\n",
    "        # Compute Spearman correlation on raw (non-log) data\n",
    "        spearman_r, _ = spearmanr(x[positive_mask], y[positive_mask])\n",
    "        # Compute Pearson correlation on log-transformed data\n",
    "        pearson_r, _ = pearsonr(x_log, y_log)\n",
    "\n",
    "    # Plot annotations\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\n",
    "        f'Spearman r = {spearman_r:.2f}\\nPearson r (log10) = {pearson_r:.2f}',\n",
    "        xy=(0.5, 0.1), \n",
    "        xycoords=ax.transAxes, \n",
    "        ha='center', \n",
    "        fontsize=12\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009ad49-5d4e-4ca0-910d-88b2257c8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.pairplot(qcdf3_180.drop(columns=['Time', 'sample']), plot_kws={\"marker\": \"x\", \"alpha\": 0.6}, corner=True)\n",
    "p.set(xscale=\"log\", yscale=\"log\")\n",
    "p.map_lower(corrfunc_pair)\n",
    "plt.savefig('sortseq_v_treblseqUMI_<date>.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf00dce-7991-4b88-8aa5-35cce9deb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = qcdf3_180['A_norm_rpm']\n",
    "y = qcdf3_180['R_norm_rpm']\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(data=qcdf3_180, x='A_norm_rpm', y='R_norm_rpm', marker='x')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add y = x line\n",
    "min_val = max(min(x.min(), y.min()), 1e-3)  # avoid log(0)\n",
    "max_val = max(x.max(), y.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Add title\n",
    "plt.title('AD reads per million vs RPTR reads per million')\n",
    "\n",
    "# Add correlation text\n",
    "corrfunc_pair(x.values, y.values)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ADreads_vs_RPTRreads_<date>.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca2268-304a-4156-a6c0-7f9d2183dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to plot as horizontal lines: medians for the ratio sort bins\n",
    "bin_medians = [7575.5, 17142.5, 25459.0, 36406.0, 52364.0, 76287.0, 126676.0, 262143.0]\n",
    "\n",
    "# Plot\n",
    "x = qcdf3_180['Ratio_negCTRLnorm']\n",
    "y = qcdf3_180['Activity_SCglucose']\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(data=qcdf3_180, y='Activity_SCglucose', x='Ratio_negCTRLnorm', marker='x')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add horizontal lines\n",
    "for y_val in bin_medians:\n",
    "    plt.axhline(y=y_val, color='red', linestyle='--', linewidth=0.8)\n",
    "\n",
    "# Title and annotation\n",
    "plt.title('Sortseq vs TREBLseq scores')\n",
    "corrfunc_pair(x.values, y.values)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sortseq_vs_TREBLseq_<date>.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b8d0e-58ac-4643-8922-e44e47574b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to plot as horizontal lines: medians for the GFP sort bins\n",
    "BYS4_1AGFP = [285,2109,3769,8782]\n",
    "BYS4_4BGFP = [256,2068,3724,9064]\n",
    "GFP_bin_medians = [sum(vals) / len(vals) for vals in zip(BYS4_1AGFP, BYS4_4BGFP)]\n",
    "\n",
    "# Plot\n",
    "x = qcdf3_180['Ratio_negCTRLnorm']\n",
    "y = qcdf3_180['GFP_mean']\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(data=qcdf3_180, y='GFP_mean', x='Ratio_negCTRLnorm', marker='x')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add horizontal lines\n",
    "for y_val in GFP_bin_medians:\n",
    "    plt.axhline(y=y_val, color='red', linestyle='--', linewidth=0.8)\n",
    "\n",
    "# Title and annotation\n",
    "plt.title('Sortseq GFP vs TREBLseq scores')\n",
    "corrfunc_pair(x.values, y.values)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca6322-da00-4bd4-981d-5245057a6925",
   "metadata": {},
   "source": [
    "# Step 3: Generate traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb6906-226d-449d-9c09-2232a0cbedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in facs csv with activity data and control designation (EC did by hand in excel)\n",
    "facs_f='Gcn4OrthologData_ToShare_20240930_EC.csv'\n",
    "facsdf = pd.read_csv(facs_f, usecols=['Name','ArrayDNA','is_control','Activity_SCglucose']).dropna()\n",
    "\n",
    "# inner join the df's \n",
    "intersectiondf = pd.merge(concatenated_df, facsdf,\n",
    "                   left_on = 'Tile', right_on = 'ArrayDNA',\n",
    "                   how= 'inner')\n",
    "intersectiondf = intersectiondf.drop(columns=['ArrayDNA', ])\n",
    "intersectiondf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa345dd-1333-4a8c-84dc-c9d02c0686e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers using the IQR method for each time group\n",
    "def remove_outliers(df, group_col, target_col):\n",
    "    \"\"\"\n",
    "    Distribution is non-parametric (skewed to the left, see lab notebook November 19, 2024), so we will keep the IQR method for calculating outliers\n",
    "    \"\"\"\n",
    "    def filter_outliers(group):\n",
    "        q1 = group[target_col].quantile(0.25) #finding IQR\n",
    "        q3 = group[target_col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr # establish bounds of IQR\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        return group[(group[target_col] >= lower_bound) & (group[target_col] <= upper_bound)] # for a group return only those that are within IQR\n",
    "\n",
    "    return df.groupby(group_col, group_keys=False)[list(set(['Tile','sample','Name', target_col, 'Time', 'BCs', 'A_norm_rpm', 'R_norm_rpm', 'Ratio']))].apply(filter_outliers) # group by a column, find IQR, return non-outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c3d99-0485-462c-a51e-0ad0e4c343da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: \n",
    "# 1. You might have to change the sample names here* (see below) based on what you called them when you gave them names in the 'Library' Column earlier.\n",
    "# 2. Or, if you've saved/re-read in the intersection df from csv, you'll want those to be int types not string type\n",
    "# 3. We gotta fix the barcodes at some point but\n",
    "\n",
    "def tile_and_replicate_hillfxn(tile, scoretype, outliers_removed=True, save_fig=False):\n",
    "    \"\"\"\n",
    "    Generate subplots for:\n",
    "    1. Ratio vs. Time for a single sample, showing individual replicates (BCs) with their mean and standard deviation.\n",
    "    2. Ratio vs. Time for multiple samples, showing individual sample lines with overall mean and standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "    tile (str): The tile to plot.\n",
    "    scoretype (str): Column that you want to run the time analysis\n",
    "    outliers_removed (bool): Whether to remove outliers (based on IQR).\n",
    "    save_fig (bool): save the figure as the tile name\n",
    "    \"\"\"\n",
    "    tiledf = intersectiondf.copy(deep=True)\n",
    "    single_sample_df2 = tiledf[(tiledf['Tile'] == tile) & (tiledf['sample'] == '2')] # Here *\n",
    "    single_sample_df3 = tiledf[(tiledf['Tile'] == tile) & (tiledf['sample'] == '3')] # Here *\n",
    "    single_sample_df4 = tiledf[(tiledf['Tile'] == tile) & (tiledf['sample'] == '4')] # Here *\n",
    "    \n",
    "    all_samples_df = tiledf[tiledf['Tile'] == tile]\n",
    "    tile_name = next(iter(set(all_samples_df['Name'].to_list())))\n",
    "    tile_name = \"_\".join(tile_name.split(\"|\")[:3])\n",
    "    \n",
    "    if outliers_removed:\n",
    "        single_sample_df2 = remove_outliers(single_sample_df2, group_col='Time', target_col=scoretype)\n",
    "        single_sample_df3 = remove_outliers(single_sample_df3, group_col='Time', target_col=scoretype)\n",
    "        single_sample_df4 = remove_outliers(single_sample_df4, group_col='Time', target_col=scoretype)\n",
    "        all_samples_df = remove_outliers(all_samples_df, group_col='Time', target_col=scoretype)\n",
    "    \n",
    "    replicate_means2 = single_sample_df2.groupby(['Time', 'BCs'])[scoretype].mean().reset_index()\n",
    "    replicate_means3 = single_sample_df3.groupby(['Time', 'BCs'])[scoretype].mean().reset_index()\n",
    "    replicate_means4 = single_sample_df4.groupby(['Time', 'BCs'])[scoretype].mean().reset_index()\n",
    "    \n",
    "    single_time_means2 = single_sample_df2.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    single_time_means3 = single_sample_df3.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    single_time_means4 = single_sample_df4.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    sample_means = all_samples_df.groupby(['Time', 'sample'])[scoretype].mean().reset_index()\n",
    "    all_time_means = sample_means.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    unique_bcs = intersectiondf['BCs'].unique()\n",
    "    palette = sns.color_palette(\"tab20\", len(unique_bcs))\n",
    "    bc_color_map = dict(zip(unique_bcs, palette))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "    fig.suptitle(f'Tile {tile_name}: Ratio (normalized) vs. Time', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, (replicate_means, single_time_means, title, ax) in enumerate(\n",
    "        zip([replicate_means2, replicate_means3, replicate_means4],\n",
    "            [single_time_means2, single_time_means3, single_time_means4],\n",
    "            ['Single Sample (Sample 1)', 'Single Sample (Sample 2)', 'Single Sample (Sample 3)'],\n",
    "            axes[:3])\n",
    "    ):\n",
    "        sns.lineplot(data=replicate_means, x='Time', y=scoretype, hue='BCs', ax=ax, alpha=0.6, lw=1.5, palette=bc_color_map)\n",
    "        ax.errorbar(single_time_means['Time'], single_time_means['mean'], yerr=single_time_means['std'], fmt='o-', capsize=5, capthick=2, color='black', label='Overall Mean ± Std Dev', lw=2, alpha=0.7)\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(f'{scoretype}')\n",
    "        ax.set_xlabel('Time (min)')\n",
    "        ax.legend(title='Replicates', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    sns.lineplot(data=sample_means, x='Time', y=scoretype, hue='sample', ax=axes[3], palette='viridis', alpha=0.85, lw=1.5)\n",
    "    axes[3].errorbar(all_time_means['Time'], all_time_means['mean'], yerr=all_time_means['std'], fmt='o-', capsize=5, capthick=2, color='red', label='Overall Mean ± Std Dev', lw=2, alpha=0.5)\n",
    "    axes[3].set_title('All Samples')\n",
    "    axes[3].set_ylabel(f'{scoretype}')\n",
    "    axes[3].set_xlabel('Time (min)')\n",
    "    axes[3].legend(title='Sample', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[3].grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_fig:\n",
    "        plt.savefig(f'{tile_name}_{scoretype}_timeseries.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    return tile_name, all_time_means['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca09c49-e658-44b0-be92-02fbb25d99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 tiles with the most unique rptr barcodes\n",
    "top_tiles_intersect = intersectiondf.groupby('Tile')['BCs'].nunique().reset_index()\n",
    "top_tiles_sorted_intersect = top_tiles_intersect.sort_values('BCs', ascending=False)\n",
    "top_10_tiles_intersect = top_tiles_sorted_intersect.head(10)['Tile']\n",
    "\n",
    "mean_dict1 = {}\n",
    "for t in top_10_tiles_intersect.to_list():\n",
    "    print(t)\n",
    "    name, mean = tile_and_replicate_hillfxn(t, 'Ratio_negCTRLnorm')\n",
    "    mean_dict1[name] = mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6c469-62af-4f6b-980d-c3a66da3bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot those top 10 in one plot\n",
    "name_list1 = list(mean_dict1.keys())\n",
    "mean_list1 = list(mean_dict1.values())\n",
    "times_series= pd.Series([0,5,10,15,30, 180, 240])\n",
    "df1 = pd.concat(mean_list1, axis=1,keys= name_list1)\n",
    "df1 = df1.set_index(times_series)\n",
    "# df.head()\n",
    "sns.lineplot(data=df1)\n",
    "plt.legend(title='Sample', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylabel('Ratio (normalized)')\n",
    "plt.xlabel('Time (min)')\n",
    "plt.title('Top 10 tiles: ratio activity score over time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7b656-84d6-485a-a00a-b02266fa8a7d",
   "metadata": {},
   "source": [
    "# Step 3.1: Trace QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420a327-52b1-45f6-b613-64c74d19d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on AD stability\n",
    "\n",
    "#FIX THIS\n",
    "\n",
    "def AD_tile_and_replicate_hillfxn(tile, scoretype, outliers_removed=True, save_fig=False):\n",
    "    \"\"\"\n",
    "    Generate subplots for:\n",
    "    1. Ratio vs. Time for a single sample, showing individual replicates (BCs) with their mean and standard deviation.\n",
    "    2. Ratio vs. Time for multiple samples, showing individual sample lines with overall mean and standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "    tile (str): The tile to plot.\n",
    "    outliers_removed (bool): Whether to remove outliers (based on IQR).\n",
    "    \"\"\"\n",
    "    tiledf = intersectiondf.copy(deep=True)\n",
    "    single_sample_df2 = tiledf[(tiledf['Tile'] == tile) & (tiledf['sample'] == '2')]\n",
    "    # print(single_sample_df2.head())\n",
    "    single_sample_df3 = tiledf[(tiledf['Tile'] == tile) & (tiledf['sample'] == '3')]\n",
    "    single_sample_df4 = tiledf[(tiledf['Tile'] == tile) & (tiledf['sample'] == '4')]\n",
    "    \n",
    "    all_samples_df = tiledf[tiledf['Tile'] == tile]\n",
    "    tile_name = next(iter(set(all_samples_df['Name'].to_list())))\n",
    "    tile_name = \"_\".join(tile_name.split(\"|\")[:3])\n",
    "    \n",
    "    if outliers_removed:\n",
    "        single_sample_df2 = remove_outliers(single_sample_df2, group_col='Time', target_col=scoretype)\n",
    "        single_sample_df3 = remove_outliers(single_sample_df3, group_col='Time', target_col=scoretype)\n",
    "        single_sample_df4 = remove_outliers(single_sample_df4, group_col='Time', target_col=scoretype)\n",
    "        all_samples_df = remove_outliers(all_samples_df, group_col='Time', target_col=scoretype)\n",
    "    \n",
    "    replicate_means2 = single_sample_df2.groupby(['Time', 'Tile-AD'])[scoretype].mean().reset_index()\n",
    "    # print(replicate_means2)\n",
    "    replicate_means3 = single_sample_df3.groupby(['Time', 'Tile-AD'])[scoretype].mean().reset_index()\n",
    "    replicate_means4 = single_sample_df4.groupby(['Time', 'Tile-AD'])[scoretype].mean().reset_index()\n",
    "    \n",
    "    single_time_means2 = single_sample_df2.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    # print(single_time_means2)\n",
    "    single_time_means3 = single_sample_df3.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    single_time_means4 = single_sample_df4.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    sample_means = all_samples_df.groupby(['Time', 'sample'])[scoretype].mean().reset_index()\n",
    "    all_time_means = sample_means.groupby('Time')[scoretype].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    unique_bcs = intersectiondf['Tile-AD'].unique()\n",
    "    palette = sns.color_palette(\"tab20\", len(unique_bcs))\n",
    "    bc_color_map = dict(zip(unique_bcs, palette))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "    fig.suptitle(f'Tile {tile_name}: Ratio (normalized) vs. Time', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, (replicate_means, single_time_means, title, ax) in enumerate(\n",
    "        zip([replicate_means2, replicate_means3, replicate_means4],\n",
    "            [single_time_means2, single_time_means3, single_time_means4],\n",
    "            ['Single Sample (Sample 2)', 'Single Sample (Sample 3)', 'Single Sample (Sample 4)'],\n",
    "            axes[:3])\n",
    "    ):\n",
    "        sns.lineplot(data=replicate_means, x='Time', y=scoretype, hue='Tile-AD', ax=ax, alpha=0.6, lw=1.5, palette=bc_color_map)\n",
    "        ax.errorbar(single_time_means['Time'], single_time_means['mean'], yerr=single_time_means['std'], fmt='o-', capsize=5, capthick=2, color='black', label='Overall Mean ± Std Dev', lw=2, alpha=0.7)\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(f'{scoretype}')\n",
    "        ax.set_xlabel('Time (min)')\n",
    "        ax.legend(title='Replicates', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    sns.lineplot(data=sample_means, x='Time', y=scoretype, hue='sample', ax=axes[3], palette='viridis', alpha=0.85, lw=1.5)\n",
    "    axes[3].errorbar(all_time_means['Time'], all_time_means['mean'], yerr=all_time_means['std'], fmt='o-', capsize=5, capthick=2, color='red', label='Overall Mean ± Std Dev', lw=2, alpha=0.5)\n",
    "    axes[3].set_title('All Samples')\n",
    "    axes[3].set_ylabel(f'{scoretype}')\n",
    "    axes[3].set_xlabel('Time (min)')\n",
    "    axes[3].legend(title='Sample', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[3].grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    if save_fig:\n",
    "        plt.savefig(f'{tile_name}_{scoretype}_timeseries.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    return tile_name, all_time_means['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665eef0-bca0-4598-84b4-e654e09ad16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against what we ran in RPTR\n",
    "for t in top_10_tiles_intersect.to_list():\n",
    "    name, mean = tile_and_replicate_hillfxn(t, 'A_norm_rpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab3dc1-f1eb-48bd-bbd0-0bc51aef0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in AD_top_10_tiles_intersect.to_list():\n",
    "    name, mean = tile_and_replicate_hillfxn(t, 'R_norm_rpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939b592-1cdb-4a86-8376-a26d2ebc3a1b",
   "metadata": {},
   "source": [
    "# Step 4: T1/2 and Vmax\n",
    "Note: this is the roughest analysis :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989e839-40d2-4b30-bc79-4ecf135e6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_fast(df, group_cols, value_col):\n",
    "    \"\"\"Remove outliers based on IQR efficiently without using apply\"\"\"\n",
    "    # Compute Q1 and Q3 per group\n",
    "    q1 = df.groupby(group_cols)[value_col].transform(lambda x: x.quantile(0.25))\n",
    "    q3 = df.groupby(group_cols)[value_col].transform(lambda x: x.quantile(0.75))\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define outlier bounds\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # Apply filtering in a vectorized manner\n",
    "    return df[(df[value_col] >= lower_bound) & (df[value_col] <= upper_bound)]\n",
    "    \n",
    "def filter_by_maximum_threshold(df, threshold=5):\n",
    "    \"\"\"Keep tiles where max value is at least `threshold` units higher than value at time 0.\"\"\"\n",
    "    return df[(df.iloc[:,:7].max(axis=1) - df.iloc[:, 0]) >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29413b95-b21e-4c5c-a20d-b7105f5b6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each (Tile, Time, Sample) combination\n",
    "tile_time_sample_counts = concatenated_df.groupby('Tile')['sample'].nunique()\n",
    "# Identify tiles that appear in all time points\n",
    "valid_tiles = tile_time_sample_counts[tile_time_sample_counts==3].index\n",
    "# Filter concatenated_df to only keep valid Tiles\n",
    "filtered_cat_1 = concatenated_df[concatenated_df['Tile'].isin(valid_tiles)]\n",
    "# Check how many tiles were removed\n",
    "print(f\"Original Tiles: {concatenated_df['Tile'].nunique()}, Filtered Tiles: {filtered_cat_1['Tile'].nunique()}\")\n",
    "\n",
    "# Remove outliers within each sample\n",
    "filtered_cat_2 = remove_outliers_fast(filtered_cat_1, ['sample', 'Tile', 'Time'], 'Ratio_negCTRLnorm')\n",
    "\n",
    "# Compute sample-level means\n",
    "sample_means_cat = filtered_cat_2.groupby(['Tile', 'Time', 'sample'])['Ratio_negCTRLnorm'].mean().reset_index()\n",
    "\n",
    "# Compute the mean across samples (not just raw mean)\n",
    "final_means_cat = sample_means_cat.groupby(['Tile', 'Time'])['Ratio_negCTRLnorm'].mean().unstack(level='Time')\n",
    "\n",
    "# Compute standard deviation across sample means\n",
    "std_devs_cat = sample_means_cat.groupby(['Tile', 'Time'])['Ratio_negCTRLnorm'].std().unstack(level='Time')\n",
    "\n",
    "# filter based on the difference between score at t=0 and Vmax\n",
    "filtered_final_means_cat = filter_by_maximum_threshold(final_means_cat).dropna()\n",
    "\n",
    "final_means_cat['Vmax'] = final_means_cat.max(axis=1)\n",
    "final_means_cat['Avg_StdDev'] = std_devs_cat.mean(axis=1)\n",
    "\n",
    "\n",
    "filtered_final_means_cat['Activity'] = 'active'\n",
    "\n",
    "inactive = final_means_cat.copy(deep=True)\n",
    "inactive = inactive.reset_index()\n",
    "inactive = inactive[~inactive['Tile'].isin(list(filtered_final_means_cat.index))].dropna()\n",
    "inactive['Activity'] = 'inactive'\n",
    "\n",
    "\n",
    "# Display the result\n",
    "filtered_final_means_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd613ff-5e65-47b4-951d-13a7f704826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fade49-7eb4-4bc7-a167-3e0c24fdb12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f528761d-ab5a-4aeb-937d-eb35f596c6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227ae30-d83c-40b5-8c8b-5073afbf2812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5857fb-4c02-4e10-bb5e-c263ae6dc2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18905a05-bf29-432e-a7be-5bc5326a9288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
